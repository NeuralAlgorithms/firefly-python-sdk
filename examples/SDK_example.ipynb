{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "SDK_example_new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CTtTiwbMJ6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install --quiet -U fireflyai\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOmx7OoRMLoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title #Import firefly.ai library {display-mode: \"form\"}\n",
        "\n",
        "import fireflyai as firefly\n",
        "from fireflyai.version import __version__\n",
        "print(\"Firefly SDK version {}\".format(__version__))\n",
        "\n",
        "import pandas as pd\n",
        "import time, os, collections, getpass, pprint, urllib3\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d42jQLAvMJ6v",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title #Login to Firefly platform \n",
        "#@markdown * Using authenticate(username, password)\n",
        "\n",
        "USER = input(\"User:\")\n",
        "PASSWORD = getpass.getpass(\"Password:\")\n",
        "try:\n",
        "    firefly.authenticate(username=USER, password=PASSWORD)\n",
        "    print(\"{} - Login successful\".format(USER))\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5oeMl8YvMJ68",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title #Example classification dataset UCI Car.\n",
        "#@markdown * Example of full loop using dataset \"UCI_Car\" \n",
        "#@markdown * It is a classification task (multi-class) \n",
        "\n",
        "PATH=\"https://raw.githubusercontent.com/NeuralAlgorithms/firefly-python-sdk/master/examples/\"\n",
        "\n",
        "data_name='car_sdk_demo'\n",
        "\n",
        "df = pd.read_csv(PATH+data_name+\".csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI99rzJMJ7K",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp5u8jNyMJ7L",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title #Uploading a Data source\n",
        "#@markdown * Use firefly.Datasource.create_from_dataframe to upload a Dataframe\n",
        "#@markdown * Use firefly.Datasource.create to upload a CSV file\n",
        "\n",
        "#@markdown * wait=True ----> wait until the upload and analysis of the data is completed. \n",
        "#@markdown * wait=False -----> return immediately \n",
        "\n",
        "try:\n",
        "    source_id = firefly.Datasource.create_from_dataframe(df=df, \n",
        "                                   data_source_name=data_name, \n",
        "                                   wait=True, skip_if_exists=True)['id']\n",
        "    print (\"\\nYour Source ID for {} is: {}\".format(data_name, source_id))\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE2-loZPMJ7U",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title #Getting the list of uploaded data sources\n",
        "#@markdown * Use firefly.list_datasources() \n",
        "\n",
        "list_sources = firefly.Datasource.list()\n",
        "sources = pd.DataFrame(list_sources['hits'])\n",
        "\n",
        "sources[[ 'creation_date', 'data_size',  'id',\n",
        "        'name', 'row_count', 'state',]].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apsDSxUCMJ7e",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title # Preparing a Dataset\n",
        "#@markdown # In this step we will define the Target and the task-type:\n",
        "\n",
        "data_set_name = data_name\n",
        "\n",
        "\n",
        "target = 'class' #@param {type:'string'}\n",
        "\n",
        "#@markdown # Select Machine learning task-type:\n",
        "\n",
        "#@markdown * Regression\n",
        "#@markdown * Classification\n",
        "#@markdown * Anomaly Detection\n",
        "#@markdown * Time-series Regression/Classification\n",
        "\n",
        "Task_Type_select = 'firefly.enums.ProblemType.CLASSIFICATION' #@param['firefly.enums.ProblemType.REGRESSION', 'firefly.enums.ProblemType.CLASSIFICATION', 'firefly.enums.ProblemType.ANOMALY_DETECTION']\n",
        "Task_Type = eval(Task_Type_select)\n",
        "print ('Your selected Target (y_value) is:', target)\n",
        "print ('Task Type is:', Task_Type.value)\n",
        "\n",
        "#@markdown # Use firefly.firefly.Datasource.prepare_data()\n",
        "\n",
        "try:\n",
        "    dataset_id = firefly.Datasource.prepare_data( \n",
        "                    datasource_id=source_id, \n",
        "                    dataset_name=data_set_name,\n",
        "                    target=target, \n",
        "                    # header=True,\n",
        "                    problem_type=Task_Type,\n",
        "                    sample_id=['car_id'],\n",
        "                    retype_columns={'car_id': firefly.enums.FeatureType.CATEGORICAL},\n",
        "                    wait=True, skip_if_exists=True)['id']\n",
        "    print(\"Dataset {} id is {}\".format( data_set_name, dataset_id))\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAQ6VeDFMJ7t",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqVoF_nAMJ7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title # List the datasets \n",
        "#@markdown * use firefly.Dataset.list()\n",
        "\n",
        "list_datasets = firefly.Dataset.list()\n",
        "datasets = pd.DataFrame(list_datasets['hits'])\n",
        "datasets.set_index('creation_date')\n",
        "datasets[[ 'creation_date',  'id', 'name',  'problem_type', 'row_count', 'state']].head(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mccbg47hMJ71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title # Get list of available pipelines/estimators:\n",
        "#@markdown * estimator list use firefly.Dataset.get_available_estimators()\n",
        "#@markdown * estimator list use firefly.Dataset.get_available_pipeline()\n",
        "\n",
        "from fireflyai.enums import InterpretabilityLevel as interpt\n",
        "precise_estimators=firefly.Dataset.get_available_estimators(inter_level=interpt.PRECISE,id=dataset_id)\n",
        "precise_pipeline=firefly.Dataset.get_available_pipeline(inter_level=interpt.PRECISE,id=dataset_id)\n",
        "simple_estimators=firefly.Dataset.get_available_estimators(inter_level=interpt.EXPLAINABLE, id=dataset_id)\n",
        "simple_pipeline=firefly.Dataset.get_available_pipeline(inter_level=interpt.EXPLAINABLE, id=dataset_id)\n",
        "\n",
        "print(\"List of all estimators:\\n {}\".format([x.value for x in precise_estimators]))\n",
        "print(\"\\nA simple pipeline:\\n {}\".format([x.value for x in simple_pipeline]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2XOMNAXMJ77",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCmybBZZMJ78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title # Training a model\n",
        "#@markdown * Choose metric\n",
        "\n",
        "Target_metric_selection = 'firefly.enums.TargetMetric.RECALL_MACRO' #@param['firefly.enums.TargetMetric.RECALL_MACRO', 'firefly.enums.TargetMetric.F1', 'firefly.enums.TargetMetric.F2', 'Normalized Gini', 'AUC', 'Log loss', 'Accuracy', 'MAE', 'Normalized MSE', 'Normalized RMSE', 'Normalized MAE', 'Median AE', 'R2', 'RMSPE', 'RMSLE', 'MAPE']\n",
        "Target_metric = eval(Target_metric_selection)\n",
        "\n",
        "#@markdown * Allocate training time\n",
        "Training_time_in_minutes = 6 #@param {type:'number'}\n",
        "\n",
        "\n",
        "#@markdown * Data partitioning \n",
        "#@markdown * Hold-out // Cross-Validation\n",
        "\n",
        "\n",
        "CV_folds = 3 #@param {type:'number'}\n",
        "interpretability_level_select = 'Explainable' #@param['Explainable', 'Precise']\n",
        "\n",
        "if interpretability_level_select=='Precise':\n",
        "  pipeline=precise_pipeline\n",
        "  estimators=precise_estimators\n",
        "  ensemble_size=5\n",
        "  interpretability_level = firefly.enums.InterpretabilityLevel.PRECISE\n",
        "else:\n",
        "  pipeline=simple_pipeline\n",
        "  estimators=simple_estimators\n",
        "  ensemble_size=5\n",
        "  interpretability_level = firefly.enums.InterpretabilityLevel.EXPLAINABLE\n",
        "\n",
        "\n",
        "print ('The training time is:', Training_time_in_minutes)\n",
        "# print ('The selected Target Metric is:', Target_metric.value)\n",
        "\n",
        "try:\n",
        "    task= firefly.Dataset.train( \n",
        "        task_name=data_name + \" \" + interpretability_level.name,\n",
        "        estimators=estimators,\n",
        "        pipeline=pipeline,\n",
        "        target_metric= Target_metric,\n",
        "        dataset_id=dataset_id,\n",
        "        # splitting_strategy=firefly.enums.SplittingStrategy.STRATIFIED,\n",
        "        notes='demo created from SDK',\n",
        "        ensemble_size=ensemble_size,\n",
        "        n_folds = CV_folds,\n",
        "        max_models_num=None,\n",
        "        interpretability_level=interpretability_level,\n",
        "        timeout=Training_time_in_minutes*60, wait=True, skip_if_exists=True\n",
        "    )\n",
        "    task_id=task['id']\n",
        "    print(\"Task info:\")\n",
        "    pprint.pprint(task.to_dict())\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SegXWFl8hdnk",
        "colab": {}
      },
      "source": [
        "#@title # List tasks\n",
        "#@markdown * Use firefly.Task.list()\n",
        "# list tasks\n",
        "\n",
        "list_tasks = firefly.Task.list()\n",
        "tasks = pd.DataFrame(list_tasks['hits'])\n",
        "\n",
        "tasks.columns\n",
        "tasks[['creation_date', 'dataset_id',  'name', 'notes', 'problem_type',\n",
        "        'state', 'target_metric']].head(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J01BO4d7hdnf",
        "colab": {}
      },
      "source": [
        "#@title List ensembles\n",
        "#@markdown * Use firefly.Ensemble.list()\n",
        "print(\"task_id for \", data_name, \" is \", task_id)\n",
        "\n",
        "#get list of ensembles\n",
        "ensembles=firefly.Ensemble.list(filter_={'task_id':[task_id],'stage': ['TASK', 'REFIT'] })['hits']\n",
        "\n",
        "n_ensembles=len(ensembles)\n",
        "if (n_ensembles>=1):\n",
        "    for i in range(n_ensembles):\n",
        "        ensemble_id = ensembles[i]['id']\n",
        "        print(\"Ensemble id {} created on {}\".format(ensemble_id, ensembles[i]['creation_date']))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjIw9F6_MJ8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Model sensitivity report { run: \"auto\" }\n",
        "\n",
        "df=pd.DataFrame()\n",
        "n=4\n",
        "alg='Permutation' #@param['Permutation', 'NA value']\n",
        "\n",
        "sens=None\n",
        "\n",
        "while (True):\n",
        "    try:\n",
        "        sens = firefly.Ensemble.get_model_sensitivity_report(id=ensemble_id)\n",
        "        if sens is not None:\n",
        "            break\n",
        "        time.sleep(5)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        break\n",
        "    \n",
        "sensp=sens[alg]\n",
        "\n",
        "df['features']=sensp.keys()\n",
        "df['importance']=sensp.values()\n",
        "\n",
        "df=df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(\"Top {0} important features by {1}:\".format(n, alg))\n",
        "\n",
        "pprint.pprint(df[:n].set_index('features'))\n",
        "\n",
        "\n",
        "y_pos = np.arange(len(df.features))\n",
        "\n",
        "plt.bar(y_pos, df['importance'], align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, df.features)\n",
        "plt.ylabel('Relative importance')\n",
        "plt.title('Sensitivity by {0}'.format(alg))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jT6scDX6MJ8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Running predictions\n",
        "\n",
        "#@markdown * upload predict data\n",
        "df_pred = pd.read_csv(PATH+data_name+\"_test.csv\")\n",
        "data_id=firefly.Datasource.create_from_dataframe(df=df_pred, data_source_name=data_name+\"_test.csv\",wait=True, skip_if_exists=True)['id']\n",
        "\n",
        "#@markdown * run prediction using firefly.Prediction.create\n",
        "predict_id=firefly.Prediction.create(ensemble_id=ensemble_id, data_id=data_id, wait=True)['id']\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzss_KdAMJ8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Download a prediction\n",
        "\n",
        "predict_results=firefly.Prediction.get(predict_id)\n",
        "\n",
        "download_url = predict_results['result_path']\n",
        "\n",
        "if download_url is not None:\n",
        "    df_predict = pd.read_csv(download_url) \n",
        "    pprint.pprint(df_predict.head(10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkmhFVU7MJ8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "least_important_features=list(df.sort_values(by='importance').features[-3:])\n",
        "least_important_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxrITT6tMJ81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a dataset without the 3 least important features\n",
        "\n",
        "try:\n",
        "    dataset_id = firefly.Datasource.prepare_data(\n",
        "            datasource_id=source_id, \n",
        "            dataset_name=data_name+\"_imp\",\n",
        "            target=target, \n",
        "            header=True, \n",
        "            not_used=least_important_features,\n",
        "            wait=False, skip_if_exists=True,\n",
        "            problem_type=Task_Type\n",
        "#             sample_id=['buying']\n",
        "    )['id']\n",
        "    print(dataset_id)\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zXJbu2kMJ84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#confsion example\n",
        "conf=firefly.Ensemble.get_ensemble_confusion_matrix(id=ensemble_id)['result']\n",
        "\n",
        "labels= conf[0]\n",
        "array = conf[1:]\n",
        "df_cm = pd.DataFrame(array, index = [i for i in labels],\n",
        "                  columns = labels)\n",
        "plt.figure(figsize = (5,5))\n",
        "sn.heatmap(df_cm, fmt='3',annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qle49yqJMJ8_",
        "colab_type": "text"
      },
      "source": [
        "## delete task / dataset / datasource by name\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnSU7YHTMJ9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inventory\n",
        "datasources = firefly.Datasource.list(search_term=data_name)['hits']\n",
        "datasets = firefly.Dataset.list(search_term=data_name)['hits']\n",
        "tasks = firefly.Task.list(search_term=data_name)['hits']\n",
        "\n",
        "print(\"Found {} data sources, {} datasets, {} tasks with name {}\".format(len(datasources), len(datasets), len(tasks), data_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC_hSEiHOkXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sure=input(\"Input 'Y' for deleting demo files and tasks:\")\n",
        "\n",
        "if sure=='Y':\n",
        "\n",
        "  for d in datasources:\n",
        "    firefly.Datasource.delete(d['id'])\n",
        "\n",
        "  for d in datasets:\n",
        "    firefly.Dataset.delete(d['id'])\n",
        "\n",
        "  for d in tasks:\n",
        "    firefly.Task.delete(d['id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q6OPakrvL2v",
        "colab_type": "text"
      },
      "source": [
        "[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axIeuSEiuopX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
